# 协议解析 #

通常大家以为，在浏览器上输入网址，一个回车下去，首先发生的事情应当是DNS解析。实际上，在DNS解析之前，浏览器还有很多工作要做。

在回车后，浏览器要做的第一件工作应当是协议解析。一般浏览器中都支持多种协议，例如http，https，ftp。部分浏览器还可以扩展，通过配置和插件处理其他协议，例如ed2k协议。如果没有指定协议，默认使用http。因此需要安全浏览网页时，往往需要自己输入https://。

当然，由于我们叙述最简单的情况，因此我们假定协议就是http，或者https。

# 缓存查询 #

当浏览器完成协议解析后，它会做一次缓存查询，看这个url是否已经被浏览过了。如果浏览过了，又不强制刷新，那么通常就不去继续请求。

当然，缓存有时也会坏事。例如开发中，某个网页已经更新了，但是网页的缓存周期很长，此时无论如何刷，内容都不变。有些浏览器允许强制刷新，从而忽略缓存。有些浏览器的强制刷新往往无效，需要手工清除缓存。但是我的建议是，在网页开发中尽量禁用缓存，因为开发中不需要优化性能，缓存只会碍事。

## 两级缓存机制 ##

通常浏览器会使用两级缓存，内存和硬盘。

由于浏览器每天访问的url量极大，因此大部分数据都存在于硬盘上，常规命中也命中在磁盘上，只有级少数正在使用的资源（例如其他页面正在使用）才可能命中在内存中。尽管磁盘命中非常慢，但是比网络访问还是快多了。

仅就设计的简单性而言，内存命中是没有太大意义的。如果我们无法忍受从磁盘载入的开销，从网络载入就是一个生命不能承受之重。通常内存命中的意义在于节约内存。如果服务器没有内存命中机制，那么对同样在内存中的一份资源（例如多个页面访问一个网站，那么这个网站的css/js之类的），需要从磁盘中读取两次，解析两次。

## 快速缓存查找 ##

给定一个key，寻找对应数据，有多少种算法？

我想大部分人都会习惯性的说出search tree。通常来说没什么问题，有些浏览器确实是用B+ tree来工作的。考虑到磁盘的块状读写特性，B+ tree是个合理选择。另一些则是使用hash table来工作。这并不难理解——缓存个数上限一旦设定，通常很少修改。直接分配表是个很容易的做法。和B+ tree相比，hash table的读性能更加优良一些。

## 缓存有效期计算 ##

缓存一定是有一定有效期的。常规缓存有三种淘汰出系统的途径，显式清除，超过有效期丢弃，超过容量丢弃。如果没有过期丢弃，资源可能被缓存了过长的时间，导致更新发布缓慢。DNS的通常更新周期都在数小时左右，因此通常更新一个DNS，都会有一句说明——通常24小时内起效。

网页的缓存有效期可以由http的头部指定，从5分钟到数日不等。然而如果某些长期不更新的页面突然更新，用户可能长期无法得到新页面。因此浏览器一般有机制（通常是Ctrl-F5）强制刷新内容。

## 缓存算法 ##

一般来说，常用的缓存更新算法包括最近未使用算法（NRU），先进先出算法（FIFO），最久未使用算法（LRU）这么几种。

不同缓存算法的开销和效果不大一样，针对网页而言，通常我们会预期，最近用到的页面继续会被用到，而好久不用的页面则没什么用到的机会。因此通常缓存都会使用LRU算法。

LRU是一种很简单的算法。想象有一个队列，长度是N。当每个页面被访问的时候，就加入队列最顶部。如果页面已经在队列中，则换到顶部。超出底部的页面则丢弃，超过时间限制的页面也丢弃。

如果没有超时时间，设计和实现会非常简单。如果超时时间对每个网页相同，也会非常简单。然而每个网页会独立的标记生存时间。因此整个队列中有多少页面超时？仅通过队列结构不能直观找到，必须使用O(n)量级的扫描。对于大型缓存而言，这是不可能接受的。因此通常还有一个网页超时时间的队列，通常应当用tree实现。也许用堆会更好，然而堆只有进和出操作，并没有任意一个对象的删除操作，因此在更新网页中必须使用完全初始化算法，从而造成了复杂度的增加。

# 后端转发 #

当缓存中没有命中的时候，浏览器就会把url提交给一个后端队列进行下载。这主要是出于以下几点的考虑。

## 前端响应 ##

如果浏览器的前端线程在下载过程中持续陷入，界面就会处于假死状态。我们管这种现象叫做前端无响应。因此，通常浏览器都不会让前端线程直接参与数据下载过程。

## 队列 ##

另一个需要转发后端下载的理由是队列和链接复用。

某些情况下，我们可能对一个网站开了多个页面，而这个网站的响应又比较慢。这种情况下，如果每个页面独立开启线程进行下载，可能我们会对这个网站产生出超过百个链接。

尽管这对我们的客户端没有什么影响，但是每个连接都会消耗一定的服务器资源。出于友好的角度考虑，太多的链接是没有必要的。因此我们可能设计一个请求队列，如果对某个服务器有过多的连接，就阻塞一部分的请求，直到有一个连接空闲出来为止。

另一个理由则可能对我们的客户端产生影响。当我们开了太多页面的时候（例如超过50个），每个页面访问不同网站，而且页面上的元素都很多。假定我们对每个页面都开20个连接（这不是一个太大的值），我们总计就会开启超过1000个连接。如此多的连接会对我们的系统产生不利影响，例如在大部分linux下，这会引发too many open file的错误。

## 持久化连接 ##

这个特性在http/1.1中定义，允许http请求完毕后不关闭连接。在http请求应答完成之后（甚至，从定义上说，允许在http应答完成前就开始），可以直接发送下一个请求。这样会省去tcp重新握手的时间。在部分服务器上，这还包含了线程初始化和请求级对象缓存清理的工作。

http/1.1的keep-alive特性最得服务器支持的原因，往往是因为大量的timewait。在tcp通讯中，先断线的一方需要等待2MSL，保持连接处于TIMEWAIT状态。在http通讯中，往往是服务器先断线。如果1s可以响应10k个请求的话，2MSL通常是120s。服务器上会长期堆积高达1.2M个socket处于TIMEWAIT状态。实际一般不会有如此多，在调整内核特性后，TIMEWAIT会大量减少，但是一般还有1K到100K个。我们可以预期，如果所有客户端都支持keep-alive，并且每个keep-alive传输10个文件。TIMEWAIT的理论值应当降低到原来的1/10。

apache提供了一个性能测试工具，叫做ab。使用ab的-k选项可以让ab进行keep-alive测试，从而测定某种情况下的性能。我建议你用这个工具对你的环境进行测试，看看keep-alive到底有多大的优化。

## Pipelining 管线化 ##

这个特性也是在HTTP 1.1中定义的，允许浏览器在连接建立后，在同一个连接内一口气发送若干个请求，然后服务器端再按照请求的顺序一口气返回所有的请求。如果其中有一个请求失败了，所有的请求都视为失败。

具体的请求个数依浏览器的不同而不同：IE是2个；Firefox是4个，可以通过about:config修改；Chrome默认不支持，但可以通过chrome://flags打开，也是4个。

没有规范定义，如何判断服务器是否支持管线化，所以大部分的浏览器都是采取试探做法。Chrome可以通过chrome://net-internals/#httpPipeline 查看到有哪些是capable（支持的）。

这项特性最大的用途是在处理静态文件上，可以极大的提高请求的速度，而对于动态页面的处理毫无帮助。
