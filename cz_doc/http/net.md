# DNS查询 #

说到DNS查询，多数人都不会陌生。DNS的设计目标是解决IP难于记忆的问题。时至今日，DNS已经成为重要的商业投资领域，对核心域名的抢注和买卖时有耳闻。随着搜索引擎的流行，DNS抢注的热度略有下降。但是不可否认的是，DNS和边界路由成为互联网的两大基石。无论两个中哪个出问题，都会影响大量网站和用户的访问。

## DNS设计 ##

DNS是一个主要工作在UDP53端口的简单协议。具体关于UDP的内容，可以看后文的UDP章节。

DNS也可以工作在TCP下，不过一般用户查询不使用TCP。

DNS的设计目标，是为大量互联网用户提供名字到IP，或者其他资源的解析。同时，它还需要满足以下条件。

1. 可以为某些集体划分出独立的名称空间。
2. 某个组织的名字管理，包括添加删除修改，都由这个组织自身管理。让某个组织反复到一个机构去登记修改记录，尤其是经常变化的IP地址，是不实际的。
3. 某个组织的名字，其他组织无法修改。

严格来说，这是一个分布式的数据库，具备名称空间，分布管理和高响应速度。于是，DNS设计为了目前的样子（其实里面还提供了其他特性，但是很少用到）。

1. 逻辑上说。
   1. DNS被分为了很多顶级域，例如com。
   2. 每个域可以容纳很多名字，这些名字又构成次级域，例如google.com。
   3. 每一个域名具备很多资源，例如A记录，MX记录。
2. 物理上说。
   1. 全球有13台根DNS服务器，所有顶级域变更都在这里进行。
   2. 某一个域名可以指定一种特殊的资源，NS记录，来指名这一级以下的域名由哪台服务器负责。

我们以google.com为例：

`$ dig google.com ANY
google.com.		43199	IN	NS	ns3.google.com.
google.com.		43199	IN	NS	ns1.google.com.
google.com.		43199	IN	NS	ns2.google.com.
google.com.		43199	IN	NS	ns4.google.com.`

这里说明了google有4条NS记录。

## DNS过程 ##

当一个用户发起一个DNS查询时，从理论上说，DNS查询系统应当如何工作？我们以a.b.c.d为例。

1. 首先向顶级DNS服务器查询顶级域名，检查其归属于哪个DNS服务器。在例子中，即是d。实际上这步必须省略，因为顶级域名一定在根服务器上。
2. 因此，我们的初始NS服务器是某台根域名服务器，而初始子域名是c.d。
3. 从某个域名起，问负责的NS服务器查询域名。例如从2往下，就是向根域名服务器查询a.b.c.d。
4. 可能很不幸，根域名服务器表示这不归他管。但是有一个b.c.d的NS记录，指向第二个域名服务器。
5. 于是我们的NS服务器转换，步骤跳回3。
6. 当查询NS服务器时，可能会命中一条CNAME记录。表示一个alias。
7. 于是我们跳回1，从根开始重新查询CNAME的记录。
8. 直到某次，我们获得了A记录，AAA记录，或者MX记录。

我们也可以想像，还有另外一种模式，叫做递归。差异在于，如果你所查询的服务器并没有你要的资源，只有一条NS记录或者CNAME。它会负责替代你，向其他服务器做查询。

## DNS系统组成 ##

在上面，我们提到了DNS系统中两个角色，根服务器和用户。实际上，仅仅由这两个角色是无法组成DNS系统的。有很多机构需要自己管理名字解析，例如大学，因此他们拥有自己的DNS服务器。这些服务器被称为区域服务器。一个完整的DNS系统至少需要根服务器，区域服务器和用户三种角色。

有很多机构，他们有自己的域名，但是他们不希望自己运行一台独立的名字解析服务器。然而上级服务器又要求这个域名必须提供NS记录（因为上级服务器不想帮你代管记录，或者这个记录费用很高，或者修改很繁琐）。因此他们可以向一种叫做域名服务商的机构购买域名解析服务。一台域名解析服务器可以被添加为多个子域的NS记录。当查询请求来到时，域名服务器会根据请求回应正确结果。godaddy就是一家域名服务商，他们同时具备域名注册代理，webhosting等多项业务。很多webhosting公司也有DNS服务。

域名服务商可以被看作是一种专业的，托管的区域服务器提供商。但是他们不增加新的角色。

如我们刚刚所描述的一样，完整的整个过程由客户端来完成是繁琐而低效的，因此通常我们会在某个大的网络中搭建DNS服务器，称为DNS代理。很多人在上网时，ISP商会给你提供一个DNS服务器设定。这个设定就是他们自己搭建的DNS代理。

DNS代理主要完成DNS查询工作，但是真正使得访问加速的是DNS缓存。我们后面有一个小节专门讲述DNS缓存。

## DNS报文结构 ##

DNS报文结构主要描述在rfc1035中。在这里我不赘述DNS的数据结构，简要描述一下DNS中具备的数据。

1. ID。每个DNS请求都带有一个ID，返回时通过ID来指名回应的哪个DNS请求。这点设计主要是因为UDP的无连接特性，不能通过连接来区分某个报文回应的是哪个请求。
2. QR。指名是query还是response。
3. question。包括了一系列question。
4. answer。包括了一系列answer。

每一条报文都包含了question和answer段，并没有特殊变化。只是通过QR字段来区分是请求还是回应。

这里特别描述一下域名的指针压缩表示法。在DNS数据结构中，一个域名由多个节表示，每个节包含一个字节的头和多个字节内容。

* 当头的最高两位没有置位时，头表示后续内容的长度。后续内容即是域名中的一个段。由此可知，域名中一个段最长可以达到64字节。
* 当头的最高两位置位时，后续6位和下一个字节表示偏移。这个偏移是内容相对于DNS报文头部的偏移。你需要跳到偏移处继续处理。
* 当头为0时，所有的节结束。

最后，对所有得到的段，按照先后顺序从左向右排列，以"."连接。

## DNS缓存 ##

DNS缓存和网页缓存面临同样的问题，因此同样使用LRU算法，并且TTL同时作用。

DNS的TTL远比网页麻烦。网页的生存时间通常都可以指定，而且在某些情况下，还可以强制无视缓存进行刷新。DNS通常都没有强制刷新一说。因此一旦DNS更新，必须等待TTL以确认所有缓存被刷新。

从这点看，TTL应当越短越好。然而短的TTL会造成大量DNS快速超时，服务器的压力比长的TTL更高。因此这是一个需要权衡的问题。

## 局域网内的search设定 ##

当进行局域网内的DNS设定时，通常会用到dnsmasq。这是一个DHCP服务器/DNS代理，同时还具备tftp服务器的功能。一个程序基本搞定整个网络内的基础设施。

在设定dnsmasq时，可以看到要求你对服务器设定一个domain，而后在dhcp到的DNS设定中可以看到domain和search设定为这个domain。这实际上是一种zone server的同类设定。

当某台机器进行dhcp时，有一个可选参数，叫做hostname。在/etc/dhcp/dhclient.conf中可以看到`send host-name = gethostname();`的设定。这实际上是将本机的hostname作为dhcp参数进行发送。当dhcp得到IP时，dnsmasq同时作为dns服务器，对domain所对应的zone添加了一条A记录，将hostname.domain映射到目标IP。

因此，在互联网内，可以使用hostname.domain直接访问目标机器。而由于search domain的设定，当直接查询hostname时，一样可以获得结果。

如果这台dnsmasq对外也提供服务，同时你将domain的ns记录指向这台机器，整个互联网都可以通过这个域名访问你刚刚DHCP上来的机器。

## 多记录返回 ##

某个域名可以对应到多台A记录，客户端应当随机挑选一台服务器进行访问。这是一个很简单的负载均衡技巧。

多记录返回作为LB技巧的问题在于，客户端并不知道哪台服务器有问题，哪台服务器最空闲。尽管在出错的时候，客户端可以更换一个IP，然而也有可能重新挑选到一样的IP。因此多IP返回的每个IP，都应当是可用的，稳定的。而且，多IP返回并不解决他们之间的压力均衡问题（当然，出于概率考虑，我们可以简单的认为他们的压力均衡）。

## 智能DNS ##

智能DNS是一种负载均衡技巧，而且在网络优化上更有优势。

智能DNS的服务器端，首先根据请求者的IP来分辨其物理地址（其实是不需要分辨物理地址的，只要分辨链接的逻辑拓扑就好），然后设法返回一台“最近的”服务器给客户端。因此。

1. 不同地区不同ISP请求得到的域名记录会不一致。
2. 多台服务器上的压力会不均衡。
3. 智能DNS不同于多IP返回，客户并不会得到其他服务器的地址（但是一次智能DNS可能返回多个IP）。

通常来说，网络的发展使得我们并不需要对访问哪台服务器做过多的考虑，真正用到智能DNS的地方，只有之间访问速度相对比较慢的多个大型网络。例如美国和欧洲之间，或者是电信和网通之间。。。

# udp的收发 #

## 协议分层 ##

如同我们知道的那样，网络是分层的，每层解决不同目标。网络的设计是使得这个目标的解决方案可以互相替换，而不互相影响。例如，我们将有线网络替换为无线网络的时候，并不影响网页浏览。这是因为无线网络只是修改了物理层的工作方式，对上层而言，这是透明的。

基于这个考虑，理想的网络协议栈的每层都需要对上下透明，并且互相不干扰。但是很可惜，不是所有协议都满足这点。例如非常著名的文件传输协议(ftp)在设计上就违反了这个目标，ftp的数据链接和控制链接是分离的。当需要传输数据的时候，控制链接中必须使用PORT或者PASV来显式的打开一条通道。如果使用PORT模式，则需要传递一个socket，让ftp服务器来连接你。这需要你可以监听外网端口，并开放连接。在网络安全日益糟糕的今天，这件事情不是那么容易实现。因此更加常用的模式是PASV，由服务器监听一个端口，由你去连接。传统上，这个端口是20。当然，由于连接的IP不一定是控制连接的对端IP，因此这个端口往往也是浮动的。

注意，当你在PORT内传递socket，或者在PASV中接收的时候，你需要按照特定格式来处理。直白的说，ipv4的socket可以表示为6个字节，其中4个是ip地址，2个是端口，他们按照大端点序的方式排列。对这6个字节分别转换为10进制数，以逗号分割为字符串，就是ftp的socket格式。例如socket ('localhost', 8118)，就会被转换为127,0,0,1,31,182。看清楚了么？8118 => 0x1f6b => 0x1f, 0x6b => 31,182。理所当然的，在ipv6或者其他协议上，ftp可能需要调整才能工作。这就是网络层不透明会造成的问题。

之所以ftp如此设计，是因为ftp在设计之初就考虑了很多的事情。首先是当数据链接全力工作的时候，控制链接仍旧可以做一些其他事情。其次，这个模式还允许FXP，或者分布式ftp之类的事情。例如我们在两个服务器间传输文件的时候，可以使一个服务器进入PASV模式，另一个服务器上使用PORT模式。这样可以以非常小的带宽指挥两台高带宽的服务器互相传输数据。或者我们可以将实际的数据存放在多台ftp服务器上，由一台主控ftp来分散访问。当客户端port或者pasv的时候，提供实际的服务器的socket。

然而，网络的发展使得这些设计迅速的失去了原有的意义。ssh的盛行，和ssh内通道文件传输功能合用，可以很大程度上替代FXP，在多台服务器间传输数据。在配置上，要求更少（尤其是对NAT的配置）。而分布式文件传输则进入了P2P时代。

## udp的设计目的 ##

udp层原本的目的，是为了解决ip层复用的问题。ip层提供了面向报文的，不可靠的数据报传输服务。然而，ip层不能区分发送源和接受目标。因此，在同一时间，只有一个程序可以使用网络。对于爆发增长的网络来说，这是不可接受的。尤其是服务化的系统。为了解决这个问题，人们设计出了一种机制，使得程序可以区分同一个主机上的不同程序，并分别和他们通讯。

udp的另一个目标就是校验。udp提供了16位的crc校验，以及16位的长度。其实从分层角度来说，tcp应当构架于udp之上。因为对比tcp和udp的设计目标，你会发现tcp重新实现了udp：他提供了端口，并实现了校验。这不禁使得我重新审视两者的关系，为什么tcp不是基于udp来设计呢？

一个合理的解释是，这会使得tcp/ip模型过于复杂。tcp/ip是一个简洁的协议，从最高的应用层，到最下方的链路层，仅有四层（在不讨论物理层的前提下）。如果tcp基于udp构建，势必会增加层数，加大系统的复杂度。

## udp头部和特点 ##

udp的头部非常简单，只包含四个数据。源端口，目标端口，长度，校验和。

从思考上来说，人们常会犯的一个错误是，将源和目标分开，写成srcip:srcport -> dstip\:dstport的形式。然而实际上，srcip和dstip属于ip层数据，srcport和dstport属于udp层的。

由于udp是在ip之上的一个简单封装，因此udp具有ip的一切特点。例如，udp是无序的，基于报文的。udp可以丢失，或者错乱。因此，使用udp进行通讯必须注意它和tcp的区别。

# 交换机的一个周期 #

## 双绞线和数据传输 ##

我们回到网络通讯最基本的部件——网线——上面，来讨论一次基本的通讯，实际上在网线上会发送什么。

任何计算机进行数据传输的基础都是必须存在连接，无论是有线模式，还是无线模式。我们先从最简单的一种模式——双绞线有线连接来讨论，物理层和链路层的工作法则。

虽然名为双绞线，但是实际上我们平时用的线路可不是单纯的两根线哦。常规双绞线至少是四对金属线铰接成的。根据外部是否增加金属屏蔽层，分为屏蔽双绞线(STP)和非屏蔽双绞线(UTP)。目前家庭最常用的是5类和超5类非屏蔽双绞线，按照设计，可以用于10M/100M/1000M的以太网络通讯。

双绞线的连接模式是点对点连接。老式系统中，常常可以见到集线器(HUB)。HUB的功能一方面是增强信号，另一方面，则是使得多个双绞线互相连同，变为星型模式。但是由于双绞线数据传输的特点（下面会说到），因此并不建议这么做。通常还是将多个双绞线分别从计算机上引出，连接到交换机上。从拓扑上，这仍旧是星型模式。但是由于交换机并不完全转发，因此也可以视为一台特殊的计算机。

点对点连接的接口称为RJ-45水晶头，也就是我们经常在电脑城中看到的一毛钱一个的水晶头。线和水晶头的连接有两种标准，分别是EIA-568-A和EIA-568-B。两者的分别在于，EIA-568-A是直连，而EIA-568-B是交叉。当计算机连接到交换机时，需要使用EIA-568-A和EIA-568-A的接法。而当计算机连接到计算机时，则需要EIA-568-A和EIA-568-B。由此也可以见到计算机通讯的简单（至少在制定规则的早期），就是简单的由系统和网卡将数据调制好，发送，然后由对方网卡接收而已。

在100M网络上，我们实际上只用到了4根双绞线。两根用于发送，两根用于接收，工作于差分传输模式。因此也被称为全双工。工作频率100Mbps，因此叫做百兆网络。而1000M网络上，则是八根全部用上了。4对发送数据，4对接收数据，工作频率250Mbps，因此叫做千兆网络。也许大家会疑惑，这样岂不是在发送数据的时候无法接收了？千兆网络是半双工的？按照我读到的资料，1000BASE-T使用了自适应均衡技术，使得4对线路可以在两个方向上同时传递数据。然而，这使得1000BASE-T对线路的要求比100BASE-T高出很多。所以，要做千兆网还是尽量使用6类线。

## bing ##

上面说到，HUB有个问题。HUB基本的工作原理是将所有的双绞线接到一起，因此，任意一个人的发出，其他全员都会收到。类似于小组讨论时的状况，每个人说的别人都可以听到。

大家可以思考一下，如果在这时候，有两个人一起说话会如何？很明显，没有人可以听清任何一个人说的内容。在通讯中，这个叫做碰撞。

碰撞是件很讨厌的事情，无论是在现实中还是在网络上。一旦发生碰撞，我们所说出去的内容就要作废。然后彼此协调，谁先开口。这个事情非常麻烦，相信大家都经历过，两个人彼此看着谁都不敢开口，等了半天，一开口又撞上了的情况。作为网络机制，我们规定，发现碰撞后，双方必须等待一定时间，等网络净空，然后再随机等待一定时间，再开始发送数据。这个机制称为CSMA/CD。其中第一个网络净空的时间，是和网络规模有关的，下面我们可以看到。

数据传输，尤其是长距离数据传输，比普通对话更容易发生碰撞。因为数据传输的频率异常的高。为了让读者容易了解这个事实，我们把假定扩充到非常远的距离——例如半个地球。我们不去考虑双绞线如何可能跨越半个地球的问题，仅仅讨论，如果相隔半个地球的两个人同时说话，会发生什么事情。

当地球一端的A君开始说话的时候，它觉得线路上是空的——这是当然，因为只有线路上是空的才适合说话，明明有人在说话却随便打断人家的家伙最讨厌了。然后，过了很短的一段时间，地球另一端的B君也想说话。此时A君的信号还没有传递到B君手里，于是B君开始说话。当他们都没有说完的时候，他们听到了彼此的声音，于是，碰撞发生了。

这个“很短的一段时间”是多久？光一秒可以绕地球7周半，那么跨越半个地球的时间就是1/15秒左右，保险起见，我们假定在0.1秒内开始进行数据传递都会出现问题。

0.1秒是一个太长的时间了。在千兆网中，这足够将报文发送无数次了。因此，如果网络真的这么长，当最终发生碰撞的消息传来时，A君就必须将很久以前的数据翻出来，重新传输。如果这样的话，报文在发送完成后就不能立即丢弃，而是要保存起来，定时丢弃。这极大的增加了处理的负担。

因此，以太网的长度距离是有限的。必须保证可以在最差情况下，在一个最长报文发送到网络的时间里，将数据在网络上走个来回。这样才能保证碰撞的解决都是即时的。实际的距离往往远小于这个限制。例如百兆网的长度限制就是100m。

当然，最好的方案是不会出现碰撞。因此，无论从安全角度还是从性能角度，近代以太网都不建议使用HUB，而是建议使用交换机来替代。

## 报文头部和转发端口 ##

交换机和HUB的功能类似，都是将多个设备连接起来，使他们互相间可以发送数据。但是其工作机制可以说天差地别。HUB仅仅是简单的转发数据，而交换机则介入了发送流程。当交换机工作的时候，首先交换机中的微型系统先接收来自用户的数据，然后略微的缓存数据。从缓存的头部中读取目标设备的标识，再计算出目标设备在哪个接口上。将这个报文仅转发到这个端口，而不是全部转发。因此，交换机具有三个HUB所不具备的优点。

* 保密性增强。对于源和目标不是自己的报文，设备不能获得。
* 性能增强。每个线路上都可以负载100M的速度（总速度看背板带宽），而不是总共100M，用的人越多总速度还会下降（因为碰撞损耗）。
* 长度增加。由于没有冲突问题，因此100米的限制限于交换机到设备上。设备到设备的最大距离是200m。

然而细心的人可以发现，上面略过了一个细节问题。交换机如何知道目标设备在哪个接口上？

这是MAC地址干的好事。

MAC地址是为每个网卡分配的地址。48位长，其中24位分配给厂家，24位分配给设备。一般一个子网中的MAC地址都不一样，万一出现冲突，系统中也允许手工指定一个不同的MAC地址。每个子网中，所有设备的MAC地址必须都不一样。交换机监听每个设备所发出的报文，以确定设备的MAC地址。

以太网报文的格式是，6字节目标地址，6字节源地址，两个字节的类型或者长度。所谓类型或者长度的意思是，如果数据大于0x0600(1536字节)就是类型，小于0x05DC(1500字节)就是长度，其余未定义。由于以太网最大长度只有1500字节，这样不会出错。大部分情况下，这里都应当是0x0800(IP)或者0x86DD(IPv6)。

当设备试图发送数据时，他必须知道对方的MAC地址。如果他只有IP地址，就必须通过ARP(类型0x0806)协议来找到目标设备的IP地址。当某个设备试图发出一个报文给IP1时，首先会发出ARP查询。如果IP1的MAC已经查询过了，在系统ARP缓存中可以找到。否则需要通过报文的发送和接收来获得MAC地址信息。关于ARP信息，可以通过`arp -a`来看到。

当确定IP1的MAC地址后，例如我们叫MAC1。源设备就会发出报文，从自己的MAC到MAC1。这时，交换机肯定已经知道了MAC1在哪个口上，因为发送数据前必然已经有过ARP查询了。所以，交换机会将数据转发到正确的端口上。

## 级联，STP和网络直径 ##

交换机的另一大优势是，可以多个交换机互联，以扩大网络规模。例如一台交换机可以提供24个口，两台交换机就可以提供46个口（想想为什么少了两个）。当然，非堆叠型交换机的坏处是，从一台交换机到另一台的速度限定在了100M。因此，如果有两对链路，同时从一台交换机到另一台交换机传输数据，那么理想状态下每对链路的速度是50M。而一台交换机上的两对链路则同时可以达到100M。所谓堆叠，暂时可以简单的看成是利用速度更快的内部接口来替代网线。

读过上文的同学，其实可以自行模拟级联交换机是如何工作的。

当ARP查询时，报文不但被送到了直连交换机D上，还送到了间接交换机R上。我们假定D的1接口接设备A，2接口接R。R的1接口接D(这个不需要对称)，2接口接设备B。当A发送ARP时，D将MacA绑定到了接口1上，R将MacA也绑定到了接口1上。推而广之，D上的所有设备的MAC都会被R绑定到接口1上，而R上所有设备的MAC都会被D绑定到接口2上。

这样，当A试图向B发送数据时，D会把数据送到接口2上，转交给R。而R则会将数据发送到接口2上。反之亦然，读者可以自行推理，我就不在这里罗嗦了。

然而这里有个小小的细节。如果D和R通过两个接口链接呢？这时的拓扑会形成环，而非树。此时，对ARP的广播会形成广播风暴。

首先，A向D广播了自己的MAC地址，D通过端口1转给了R。R当然不会通过源端口转回去，但是另一根线路连接到D上，这个事实R并没有意识到。于是R将这个报文放到了另一根线路上，转回给了D。两者就在里面转来转去，整个网络的路由表也会因此瘫痪。

解决这个问题十分简单，如果一个ARP广播已经经过交换机，那么就需要被识别出来，并且当重复经过的时候，报文被丢弃。实际的情况比这个复杂一点，因为线路的选择是网络初始化时决定的，而不是具体在传输报文时再进行计算，因此需要额外的协议。这样会比每次计算拥有更高的效率。而这个协议，由于可以将一个带环的图剪切为一颗最优树，因此叫做STP协议(最优生成树, Spanning Tree Protocol, IEEE 802.1D)。

当然，级联还带来一个问题。一个端口需要绑定超过1个的MAC地址。在原本的模型中，一个端口绑定一个MAC，整个设备最高只需要8个MAC地址存储器就够了。然而由于级联的存在，因此MAC表的规模会超过端口数。在级联的网络中，每个路由器的MAC表大小都等于子网内的所有带MAC设备数。于是，如果某个设备的MAC表不足，他就会出现种种问题。整个网络也不能运作。

因此，级联也有其尺寸。这个尺寸并非物理上的尺寸极限，而是一个交换机所组成的子网有其最大设备数限制。对于大部分桌面型交换机，这个数字都小于8192。而实际推荐一个子网的尺寸不应当大于256(当然，这里的原因更多是IP层的逻辑上的)。

# 无线 #

## 无线连接的物理基础 ##

无线连接是基于802.11系列协议工作的。最早的协议是802.11，速率2Mbps，使用2.4G频率。后来添加了两个扩展，a和b。a使用5G频率，速率54Mbps。b使用2.4G，速率11Mbps(其实两者差异不止如此，编码方式也有差异)。之所以使用这两个频率，是因为这是国际电信联盟无线电通信组(ITU-R)所规定的ISM频率(工业，科学和医用频率)。这两个频率在大部分国家都预留给了非执照使用，即一个通讯设备制造厂商不需要经过特别的批准和授权就可以合法的制造基于这种频率的设备。使用者也不需要特别的执照进行使用。

由于11a的调制方式更加复杂，而且将2.4G划为ISM的国家比5G也划入ISM的国家更多。而且2.4G频率具有更好的穿透性，适合广域复杂环境下使用。因此，很多手机纷纷支持802.11b标准。后来其后继者11g标准同样采用了2.4G频率，速率却有54Mbps。也让这个标准成为了无线网络通讯的事实标准。

在这里我们略微深入介绍一下2.4G频段的划分和使用。11b将2.4G的可用频率划分为互相差5MHz的14个信道(channel)。当某个通讯子网建立时，会需要选择一个信道。例如使用channel6，那么标准中心频率就是2.437GHz。此时这个通讯子网会占用至少22M的频宽(即20MHz的标准带宽)。按照此处的规定推算，假如某个AP采用channel6，实际上会干扰到channel4的通讯频率。而如果另一个AP采用channel2，则也会干扰到channel4。因此，相距小于5的两个channel之间会产生互相干扰。

某些国家还有12,13,14三个信道，然而不是每个国家都支持。美国是不支持的，因此美国产的设备连接中制路由器，路由器又恰好选择了11以上的channel时，会无法连接。

信道互相干扰引发了一个很麻烦的问题。尽管名义上我们有11个channel，然而实际不产生干扰的只有1, 6, 11三个信道。如果在互相可以通讯的距离内使用了同一信道，就会发生干扰，此时双方都无法达到满速。而且2.4G是各个国家都支持的ISM频率这点，使得蓝牙，无绳电话纷纷使用这一频率，加紧了干扰。

其次，54Mbps速度也越来越不敷使用，而且还有安全问题(下面会讲到)。各个厂商分别研发了独立于11g的技术。这些技术大行其道，却互相不兼容。在这种情况下，IEEE推出了11g的后续协议，802.11n。

11n针对上述问题做了很多改善。首先，11n的基础传输速度提升到了72M。其次，11n允许使用双倍带宽(40MHz)，此时速度可达150M。最后，11n规范了MIMO技术，允许使用多根天线加速。在使用4天线，双倍带宽时，可以达到600MHz的高速。基本达到千兆网络的一半，远远高于百兆网。而且11n使用软调制技术，可以同时作用于2.4G和5G频率，使得部分支持5G的设备可以使用空闲频率。

当然，11n也不是完美的。双倍带宽实际上恶化了干扰，将2.4G的可用信道从三个变成了两个。MIMO听上去很美，却是要多付钱的。由于空间限制，手机根本不支持。至于5G，也基于同样理由，手机不支持。更何况5G频率在各个国家的支持程度不一。这里就不对5G频率做介绍了。简单的说，5G频率拥有12条不冲突的信道，却不是在每个国家都支持。主要分为52-140频段和149-165频段。欧洲和日本支持前者，中国和新加坡支持后者，美国和台湾两者都支持。这使得设备制造上只能制造全能型设备，然后期望使用者了解自己国家的无线电常识，或者针对特定国家销售的时候通过技术手法屏蔽掉部分选项。

## 信号质量和信号衰减 ##

## 报文传输速率 ##

无线网络的一个常见问题是，为什么54M的标准只有2M出头的速度。其中的一大原因就是AP的工作机理。由于AP模式是无线链路链接到每个网卡的，因此，一个报文从设备A传递到设备B的时候，需要先传递到AP，再传递到B。这使得网络速度最高只有标准的一半——即27M。而基础网络开销又占去一部分。因此实际的平均网络吞吐预期大约是22M，合2.75M/s。

## 无线信道安全性 ##

## 无线对ip/tcp层的影响 ##

# ip包的来访 #

## ip解决什么问题 ##

## ip不解决什么问题 ##

## 如果ip比子网MTU更大 ##

# tcp握手 #

## tcp头部 ##

## socket准备 ##

## 陷入和状态改变 ##

## syn包在网络中游荡 ##

## 发出syn包后线程在做什么 ##

## syn包队列 ##

## accept和ack包 ##

## 双向序列和MTU试探 ##

## timestamp和初次rtt计算 ##

# tcp数据发送过程 #

## 发送缓冲区就绪等待 ##

## 陷入和用户态-内核态复制 ##

## 复制完成就立刻发送么 ##

## 数据报文的组成 ##

## 漂流瓶来访 ##

## 乱序？坑爹？ ##

## 有乱序就有历史 ##

## 序列回卷速度和paws ##

## 接收缓冲区和tcp recv window ##

## window scale ##

## 就绪通知方法 ##

# tcp拥塞控制 #

## 丢包和重发机制 ##

## 拥塞控制算法 ##

## pack ##

## sack ##

## 定时器 ##

# tcp的断开 #

## tcp状态管理 ##

## 半关闭的原因 ##

## timewait的原因 ##

# ssl前来插足 #

## ssl认证结构 ##

## 应该给哪张证书 ##

## openssl ##

# 代理和缓存 #

## 普通代理 ##

## 代理链和调度 ##

## 透明代理 ##

## 反向代理 ##

## 命中率 ##
